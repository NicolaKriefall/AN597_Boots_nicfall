---
title: "nicfall_originalhwcode_05"
author: "Nicola Kriefall"
date: "11/7/2019"
output: html_document
---

[Hw assignment #5](https://fuzzyatelin.github.io/bioanth-stats/homework-05.html)

1. Using the “KamilarAndCooperData.csv” dataset, run a linear regression looking at log(HomeRange_km2) in relation to log(Body_mass_female_mean) and report your β coeffiecients (slope and intercept).

```{r}
#first, reading in the data:
library(curl)
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN597_Fall19/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
str(d$HomeRange_km2) #lots of NAs 
str(d$Body_mass_female_mean) #more NAs
d_km <- d[complete.cases(d$HomeRange_km2),] #removing NAs for home range
d_full <- d_km[complete.cases(d_km$Body_mass_female_mean),] #removing NAs for body mass

#linear regression looking at log(home range) vs. log(body mass female mean)
model <- lm(log(d_full$HomeRange_km2)~log(d_full$Body_mass_female_mean),data=d_full)
model
#intercept is reportedly -9.441
#slope is reportedly 1.036
```

[2] Then, use bootstrapping to sample from your data 1000 times with replacement, each time fitting the same model and calculating the same coefficients. This generates a sampling distribution for each β coefficient.

```{r}
x <- log(d_full$Body_mass_female_mean)
y <- log(d_full$HomeRange_km2)
set.int <- NULL # sets up a dummy variable to hold our 10000 simulations
for (i in 1:1000){
  bw <- sample(x,replace=TRUE)
  km <- sample(y,replace=TRUE)
  lmz <- lm(km~bw)
  set.int[i] <- lmz[["coefficients"]][["(Intercept)"]]
}
set.slope <- NULL # sets up a dummy variable to hold our 10000 simulations
for (i in 1:1000){
  bw <- sample(x,replace=TRUE)
  km <- sample(y,replace=TRUE)
  lmz <- lm(km~bw)
  set.slope[i] <- lmz[["coefficients"]][["bw"]]
}
```

[more 2] Estimate the standard error for each of your β coefficients as the standard deviation of the sampling distribution from your bootstrap and determine the 95% CI for each of your β coefficients based on the appropriate quantiles from your sampling distribution.

```{r}
#I don't fully understand the instructions part "Estimate the standard error for each of your β coefficients as the standard deviation of the sampling distribution" - here's the stanard deviation of the sampling distribution:
sd(set.int)
sd(set.slope)

#here's the standard error:
#SE mean = (sample standard deviation) / square root of (number of observations)
se.int <- (sd(x=set.int))/sqrt(length(set.int))
se.int
se.slope <- (sd(x=set.slope))/sqrt(length(set.slope))
se.slope

#determining CI from appropriate quantiles from my sampling distribution
quantile(set.int, c(0.025, 0.975))
quantile(set.slope, c(0.025, 0.975))

## another way of measuring CI - completely different results though:
# upper.int <- mean(set.int) + qnorm(0.975, mean=0, sd=1)*se(set.int)
# lower.int <- mean(set.int) + qnorm(0.025, mean=0, sd=1)*se(set.int) 
# ci.int <- c(lower.int,upper.int)
# ci.int
# 
# upper.slope <- mean(set.slope) + qnorm(0.975, mean=0, sd=1)*se(set.slope)
# lower.slope <- mean(set.slope) + qnorm(0.025, mean=0, sd=1)*se(set.slope) 
# ci.slope <- c(lower.slope,upper.slope)
# ci.slope
```

[2 continued] How does the former compare to the SE estimated from your entire dataset using the formula for standard error implemented in lm()?

```{r}
summary(model) #my original entire dataset
#residual standard error = 1.423
#my se from intercept distribution: 0.03132988
#my se from slope distribution: 0.004052128
#they compare very differently
```

[last part of 2] How does the latter compare to the 95% CI estimated from your entire dataset?

```{r}
confint(model)
#very different
```

# Challenges

1. I don't understand why my average slope & intercept values after bootstrapping are completely off from what the real ones were from the whole dataset (see below), either I made a mistake or the sampling reduces the accuracy that much?

```{r}
mean(set.int) #bootstrapped result vs. -9.441 real value
mean(set.slope) #bootstrapped result vs. 1.036 real value
```

2. Similarly, my CI from the quantiles of my dataset vs. running this type of calculation: "lower.slope <- mean(set.slope) + qnorm(0.025, mean=0, sd=1)*se(set.slope)" were completely different - but in Chris's example on module 7, they were very similar results

3. What does this part mean: "Estimate the standard error for each of your β coefficients as the standard deviation of the sampling distribution from your bootstrap"

4. The use of "the former" & "the latter" was confusing. 

5. I think part of my issue overall is that the terminology is the same within a linear model as for a sampling distribution & I can't keep track of which we're referring to.